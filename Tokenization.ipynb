{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Tokenization with the following proces: \n",
        "\n",
        "1. Simple Tekenization with .split\n",
        "2. Tokenization with NLTK\n",
        "3. Convert a corpus to a vector of token counts with counter Vectorizer.\n",
        "4. Tokenize text in different languages with  spacy\n",
        "5. Tokenization with Gensim\n"
      ],
      "metadata": {
        "id": "04Dg1jgMDysN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.Simple Tokenization \n",
        "text = \"\"\"Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think\n",
        "that they can change the world, are the ones who do.\"\"\"\n",
        "text.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxCuPLTGDxmg",
        "outputId": "97634781-3d28-4a93-e150-f85274c2f76a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here’s',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones,',\n",
              " 'the',\n",
              " 'misfits,',\n",
              " 'the',\n",
              " 'rebels,',\n",
              " 'the',\n",
              " 'troublemakers,',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " '—',\n",
              " 'they’re',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them,',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them,',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them,',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can’t',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things.',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward,',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones,',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius,',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world,',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the split() method doesn’t consider punctuation symbols as a separate token. This might change your project results."
      ],
      "metadata": {
        "id": "CqvBzJH-Gy1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Tokenization with NLTK\n",
        "# NLTK contains a module called tokenize with a word_tokenize() method that will help us split a text into tokens."
      ],
      "metadata": {
        "id": "Sy_Jr7OSjgtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DmULbBOF3CW",
        "outputId": "d3b300e7-3c42-4b4f-b599-b1691c4b4dcf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think\n",
        "that they can change the world, are the ones who do.\"\"\"\n",
        "word_tokenize(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzxO0FgrF3F-",
        "outputId": "4c8f3967-5f89-4b3f-a38b-4984eeb9c817"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " '’',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " ',',\n",
              " 'the',\n",
              " 'misfits',\n",
              " ',',\n",
              " 'the',\n",
              " 'rebels',\n",
              " ',',\n",
              " 'the',\n",
              " 'troublemakers',\n",
              " ',',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes',\n",
              " '.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " '—',\n",
              " 'they',\n",
              " '’',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules',\n",
              " '.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them',\n",
              " ',',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them',\n",
              " ',',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " '’',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things',\n",
              " '.',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " ',',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " ',',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius',\n",
              " ',',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " ',',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Convert a corpus to a vector of token counts with Count Vectorizer (sklearn)"
      ],
      "metadata": {
        "id": "AOKoAWTKLSaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last 2 methods are not effective in dealing with a large corpus because you’ll need to represent the tokens differently. Count Vectorizer will help us convert a collection of text documents to a vector of token counts. In the end, we’ll get a vector representation of the text data."
      ],
      "metadata": {
        "id": "5v65qR-uMI38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "texts = [\n",
        "\"\"\"Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think that they can change the world, are the ones who do.\"\"\" ,\n",
        " \n",
        "'I choose a lazy person to do a hard job. Because a lazy person will find an easy way to do it.'\n",
        "]\n",
        "df = pd.DataFrame({'author': ['jobs', 'gates'], 'text':texts})"
      ],
      "metadata": {
        "id": "IHyUdEEbF3PW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# initialize\n",
        "cv = CountVectorizer(stop_words='english') \n",
        "cv_matrix = cv.fit_transform(df['text']) \n",
        "# create document term matrix\n",
        "df_dtm = pd.DataFrame(cv_matrix.toarray(), index=df['author'].values, columns=cv.get_feature_names_out())\n"
      ],
      "metadata": {
        "id": "Ek-BlgmcF3SQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dtm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "RhdOpBEXF3VY",
        "outputId": "f7544ad0-bd90-4d80-a9d5-d67892ce1256"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       change  choose  crazy  differently  disagree  easy  fond  forward  \\\n",
              "jobs        2       0      3            1         1     0     1        1   \n",
              "gates       0       1      0            0         0     1     0        0   \n",
              "\n",
              "       genius  glorify  ...  round  rules  square  thing  things  think  \\\n",
              "jobs        1        1  ...      1      1       1      1       2      1   \n",
              "gates       0        0  ...      0      0       0      0       0      0   \n",
              "\n",
              "       troublemakers  vilify  way  world  \n",
              "jobs               1       1    0      1  \n",
              "gates              0       0    1      0  \n",
              "\n",
              "[2 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb2de188-838a-44a8-90d3-4882edd4499e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>change</th>\n",
              "      <th>choose</th>\n",
              "      <th>crazy</th>\n",
              "      <th>differently</th>\n",
              "      <th>disagree</th>\n",
              "      <th>easy</th>\n",
              "      <th>fond</th>\n",
              "      <th>forward</th>\n",
              "      <th>genius</th>\n",
              "      <th>glorify</th>\n",
              "      <th>...</th>\n",
              "      <th>round</th>\n",
              "      <th>rules</th>\n",
              "      <th>square</th>\n",
              "      <th>thing</th>\n",
              "      <th>things</th>\n",
              "      <th>think</th>\n",
              "      <th>troublemakers</th>\n",
              "      <th>vilify</th>\n",
              "      <th>way</th>\n",
              "      <th>world</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>jobs</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gates</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb2de188-838a-44a8-90d3-4882edd4499e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb2de188-838a-44a8-90d3-4882edd4499e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb2de188-838a-44a8-90d3-4882edd4499e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This method is extremely useful when the dataframe contains a large corpus because it provides a matrix with words encoded as integers.\n",
        "# Count Vectorizer can have different parameters like stop_words\n",
        "# the default regexp used by Count Vectorizer selects tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator)"
      ],
      "metadata": {
        "id": "kZxstzF4F3Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Tokenize text in different languages with spaCy"
      ],
      "metadata": {
        "id": "zJFd4LUtQn-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# When you need to tokenize text written in a language other than English, you can use spaCy. "
      ],
      "metadata": {
        "id": "IvoGYXAQF3ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.es import Spanish\n",
        "nlp = Spanish()\n",
        "\n",
        "text_spanish = \"\"\"Por los locos. Los marginados. Los rebeldes. Los problematicos. \n",
        "Los inadaptados. Los que ven las cosas de una manera distinta. A los que no les gustan\n",
        "las reglas. Y a los que no respetan el “status quo”. Puedes citarlos, discrepar de ellos,\n",
        "ensalzarlos o vilipendiarlos. Pero lo que no puedes hacer es ignorarlos… Porque ellos\n",
        "cambian las cosas, empujan hacia adelante la raza humana y, aunque algunos puedan\n",
        "considerarlos locos, nosotros vemos en ellos a genios. Porque las personas que están\n",
        "lo bastante locas como para creer que pueden cambiar el mundo, son las que lo logran.\"\"\"\n",
        "\n",
        "doc = nlp(text_spanish)\n",
        "\n",
        "tokens = [token.text for token in doc]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iti8JXd6F3i-",
        "outputId": "3e6b41fa-6fc1-4e5e-ee94-4163f813bf5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Por', 'los', 'locos', '.', 'Los', 'marginados', '.', 'Los', 'rebeldes', '.', 'Los', 'problematicos', '.', '\\n', 'Los', 'inadaptados', '.', 'Los', 'que', 'ven', 'las', 'cosas', 'de', 'una', 'manera', 'distinta', '.', 'A', 'los', 'que', 'no', 'les', 'gustan', '\\n', 'las', 'reglas', '.', 'Y', 'a', 'los', 'que', 'no', 'respetan', 'el', '“', 'status', 'quo', '”', '.', 'Puedes', 'citarlos', ',', 'discrepar', 'de', 'ellos', ',', '\\n', 'ensalzarlos', 'o', 'vilipendiarlos', '.', 'Pero', 'lo', 'que', 'no', 'puedes', 'hacer', 'es', 'ignorarlos', '…', 'Porque', 'ellos', '\\n', 'cambian', 'las', 'cosas', ',', 'empujan', 'hacia', 'adelante', 'la', 'raza', 'humana', 'y', ',', 'aunque', 'algunos', 'puedan', '\\n', 'considerarlos', 'locos', ',', 'nosotros', 'vemos', 'en', 'ellos', 'a', 'genios', '.', 'Porque', 'las', 'personas', 'que', 'están', '\\n', 'lo', 'bastante', 'locas', 'como', 'para', 'creer', 'que', 'pueden', 'cambiar', 'el', 'mundo', ',', 'son', 'las', 'que', 'lo', 'logran', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  imported Spanish from spacy.lang.es but if you’re working with text in English, just import English from spacy.lang.en\n",
        "# spaCy, considers punctuation symbols as a separate token (even the new lines\\n were included)."
      ],
      "metadata": {
        "id": "gPhlrE5yROAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Tokenization with Gensim"
      ],
      "metadata": {
        "id": "5UKHXinwRtlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim is a library for unsupervised topic modeling and natural language processing and also contains a tokenizer.\n",
        "from gensim.utils import tokenize\n",
        "text = \"\"\"Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think\n",
        "that they can change the world, are the ones who do.\"\"\"\n",
        "list(tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uejheL_cRO4j",
        "outputId": "57591a63-da1d-4d39-902a-d6342d0e9943"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " 'the',\n",
              " 'misfits',\n",
              " 'the',\n",
              " 'rebels',\n",
              " 'the',\n",
              " 'troublemakers',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Gensim splits every time it encounters a punctuation symbol"
      ],
      "metadata": {
        "id": "7COV_gn1RO8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "summary: \n",
        "1. The .split method is a simple tokenizer that separates text by white spaces. \n",
        "2. NLTK and Gensim do a similar job, but with different punctuation rules.  \n",
        "3. spaCy, which offers a multilingual tokenizer and sklearn that helps tokenize a large corpus."
      ],
      "metadata": {
        "id": "xy3S9KKoS-nD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yfQkk0RES063"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}