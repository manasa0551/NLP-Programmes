{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation using LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Forget Gate: This gate decide which information is important and should be stored and which information to forget. It removes the non important information from neuron cell. \n",
        "This gate takes 2 input- one is the output generated by previous cell and other is input of current cell. Following required bias and weights are added and multiplied and sigmoid function is applied to the value. A value between 0 and 1 is generated and based on this we decide which information to keep. If value is 0 the forget gate will remove that information and if value is 1 then information is important and has to be remembered."
      ],
      "metadata": {
        "id": "yAfAThitaQ6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input Gate: This gate is used to add information to neuron cell. It is responsible of what values should be added to cell by using activation function like sigmoid. It creates an array of information that has to be added. This is done by using another activation function called tanh. It generates a values between -1 and 1. The sigmoid function act as a filter and regulate what information has to be added in cell."
      ],
      "metadata": {
        "id": "qjqTMMQkawy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Gate: This gate is responsible for selecting important information from current cell and show it as output. It creates a vector of values using tanh function which ranges from -1 to 1. It uses previous output and current input as a regulator which also includes sigmoid function and decides which values should be shown as output."
      ],
      "metadata": {
        "id": "IxDwEPysa5Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#All Libraries required \n",
        "import numpy\n",
        "import sys\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "Re5bjbSCPh6i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(\"Two-tail.txt\").read()"
      ],
      "metadata": {
        "id": "IvSFiUfCPh9v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text cannot be processed so we have to convert it to readable form.\n",
        "# This can be done by 2 methods a-one hot encoding b-word embedding.\n",
        "# 1.one hot encoding involves converting text into 1's and 0's vector. It will create \n",
        "#   bag of words which represent the freq of each word in document.\n",
        "# 2.Word embeddings represents text words a vector of real numbers. It can use more numbers than 0 and 1"
      ],
      "metadata": {
        "id": "K0PEEm0uPiBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BTfUgeOg42N",
        "outputId": "8ec68fd4-b087-4a4a-c340-fa94e083030b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "sentence=(file)\n",
        "sentence=sentence.replace('\\n',\"\")\n",
        "sentence=(sent_tokenize(sentence))\n",
        "print(sentence)"
      ],
      "metadata": {
        "id": "8Po5o1yhPiEA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836a3f17-2907-4794-a565-36587b16f875"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I.', 'The PeriodIt was the best of times,it was the worst of times,it was the age of wisdom,it was the age of foolishness,it was the epoch of belief,it was the epoch of incredulity,it was the season of Light,it was the season of Darkness,it was the spring of hope,it was the winter of despair,we had everything before us,we had nothing before us,we were all going direct to Heaven,we were all going direct the other way--in short, the period was so far like the present period, that some ofits noisiest authorities insisted on its being received, for good or forevil, in the superlative degree of comparison only.There were a king with a large jaw and a queen with a plain face, on thethrone of England; there were a king with a large jaw and a queen witha fair face, on the throne of France.', 'In both countries it was clearerthan crystal to the lords of the State preserves of loaves and fishes,that things in general were settled for ever.It was the year of Our Lord one thousand seven hundred and seventy-five.Spiritual revelations were conceded to England at that favoured period,as at this.', 'Mrs. Southcott had recently attained her five-and-twentiethblessed birthday, of whom a prophetic private in the Life Guards hadheralded the sublime appearance by announcing that arrangements weremade for the swallowing up of London and Westminster.', 'Even the Cock-laneghost had been laid only a round dozen of years, after rapping out itsmessages, as the spirits of this very year last past (supernaturallydeficient in originality) rapped out theirs.', 'Mere messages in theearthly order of events had lately come to the English Crown and People,from a congress of British subjects in America: which, strangeto relate, have proved more important to the human race than anycommunications yet received through any of the chickens of the Cock-lanebrood.France, less favoured on the whole as to matters spiritual than hersister of the shield and trident, rolled with exceeding smoothness downhill, making paper money and spending it.', 'Under the guidance of herChristian pastors, she entertained herself, besides, with such humaneachievements as sentencing a youth to have his hands cut off, his tonguetorn out with pincers, and his body burned alive, because he had notkneeled down in the rain to do honour to a dirty procession of monkswhich passed within his view, at a distance of some fifty or sixtyyards.', 'It is likely enough that, rooted in the woods of France andNorway, there were growing trees, when that sufferer was put to death,already marked by the Woodman, Fate, to come down and be sawn intoboards, to make a certain movable framework with a sack and a knife init, terrible in history.', 'It is likely enough that in the rough outhousesof some tillers of the heavy lands adjacent to Paris, there weresheltered from the weather that very day, rude carts, bespattered withrustic mire, snuffed about by pigs, and roosted in by poultry, whichthe Farmer, Death, had already set apart to be his tumbrils ofthe Revolution.', 'But that Woodman and that Farmer, though they workunceasingly, work silently, and no one heard them as they went aboutwith muffled tread: the rather, forasmuch as to entertain any suspicionthat they were awake, was to be atheistical and traitorous.In England, there was scarcely an amount of order and protection tojustify much national boasting.', 'Daring burglaries by armed men, andhighway robberies, took place in the capital itself every night;families were publicly cautioned not to go out of town without removingtheir furniture to upholsterers\\' warehouses for security; the highwaymanin the dark was a City tradesman in the light, and, being recognised andchallenged by his fellow-tradesman whom he stopped in his character of\"the Captain,\" gallantly shot him through the head and rode away; themail was waylaid by seven robbers, and the guard shot three dead, andthen got shot dead himself by the other four, \"in consequence of thefailure of his ammunition:\" after which the mail was robbed in peace;that magnificent potentate, the Lord Mayor of London, was made to standand deliver on Turnham Green, by one highwayman, who despoiled theillustrious creature in sight of all his retinue; prisoners in Londongaols fought battles with their turnkeys, and the majesty of the lawfired blunderbusses in among them, loaded with rounds of shot and ball;thieves snipped off diamond crosses from the necks of noble lords atCourt drawing-rooms; musketeers went into St. Giles\\'s, to searchfor contraband goods, and the mob fired on the musketeers, and themusketeers fired on the mob, and nobody thought any of these occurrencesmuch out of the common way.', \"In the midst of them, the hangman, ever busyand ever worse than useless, was in constant requisition; now, stringingup long rows of miscellaneous criminals; now, hanging a housebreaker onSaturday who had been taken on Tuesday; now, burning people in thehand at Newgate by the dozen, and now burning pamphlets at the door ofWestminster Hall; to-day, taking the life of an atrocious murderer,and to-morrow of a wretched pilferer who had robbed a farmer's boy ofsixpence.All these things, and a thousand like them, came to pass in and closeupon the dear old year one thousand seven hundred and seventy-five.Environed by them, while the Woodman and the Farmer worked unheeded,those two of the large jaws, and those other two of the plain and thefair faces, trod with stir enough, and carried their divine rightswith a high hand.\", 'Thus did the year one thousand seven hundredand seventy-five conduct their Greatnesses, and myriads of smallcreatures--the creatures of this chronicle among the rest--along theroads that lay before them.II.', \"The MailIt was the Dover road that lay, on a Friday night late in November,before the first of the persons with whom this history has business.The Dover road lay, as to him, beyond the Dover mail, as it lumbered upShooter's Hill.\", 'He walked up hill in the mire by the side of the mail,as the rest of the passengers did; not because they had the least relishfor walking exercise, under the circumstances, but because the hill,and the harness, and the mud, and the mail, were all so heavy, that thehorses had three times already come to a stop, besides once drawing thecoach across the road, with the mutinous intent of taking it backto Blackheath.', 'Reins and whip and coachman and guard, however, incombination, had read that article of war which forbade a purposeotherwise strongly in favour of the argument, that some brute animalsare endued with Reason; and the team had capitulated and returned totheir duty.With drooping heads and tremulous tails, they mashed their way throughthe thick mud, floundering and stumbling between whiles, as if they werefalling to pieces at the larger joints.', 'As often as the driver restedthem and brought them to a stand, with a wary \"Wo-ho!', 'so-ho-then!\"', 'thenear leader violently shook his head and everything upon it--like anunusually emphatic horse, denying that the coach could be got up thehill.', 'Whenever the leader made this rattle, the passenger started, as anervous passenger might, and was disturbed in mind.There was a steaming mist in all the hollows, and it had roamed in itsforlornness up the hill, like an evil spirit, seeking rest and findingnone.', 'A clammy and intensely cold mist, it made its slow way through theair in ripples that visibly followed and overspread one another, as thewaves of an unwholesome sea might do.', 'It was dense enough to shut outeverything from the light of the coach-lamps but these its own workings,and a few yards of road; and the reek of the labouring horses steamedinto it, as if they had made it all.Two other passengers, besides the one, were plodding up the hill by theside of the mail.', 'All three were wrapped to the cheekbones and over theears, and wore jack-boots.', 'Not one of the three could have said, fromanything he saw, what either of the other two was like; and each washidden under almost as many wrappers from the eyes of the mind, as fromthe eyes of the body, of his two companions.', 'In those days, travellerswere very shy of being confidential on a short notice, for anybody onthe road might be a robber or in league with robbers.', 'As to the latter,when every posting-house and ale-house could produce somebody in\"the Captain\\'s\" pay, ranging from the landlord to the lowest stablenon-descript, it was the likeliest thing upon the cards.', 'So the guardof the Dover mail thought to himself, that Friday night in November, onethousand seven hundred and seventy-five, lumbering up Shooter\\'s Hill, ashe stood on his own particular perch behind the mail, beating his feet,and keeping an eye and a hand on the arm-chest before him, where aloaded blunderbuss lay at the top of six or eight loaded horse-pistols,deposited on a substratum of cutlass.The Dover mail was in its usual genial position that the guard suspectedthe passengers, the passengers suspected one another and the guard, theyall suspected everybody else, and the coachman was sure of nothing butthe horses; as to which cattle he could with a clear conscience havetaken his oath on the two Testaments that they were not fit for thejourney.\"Wo-ho!\"', 'said the coachman.', '\"So, then!', 'One more pull and you\\'re at thetop and be damned to you, for I have had trouble enough to get you toit!--Joe!\"\"Halloa!\"', 'the guard replied.', '\"What o\\'clock do you make it, Joe?', '\"\"Ten minutes, good, past eleven.', '\"\"My blood!\"', 'ejaculated the vexed coachman, \"and not atop of Shooter\\'syet!', 'Tst!', 'Yah!', 'Get on with you!', '\"The emphatic horse, cut short by the whip in a most decided negative,made a decided scramble for it, and the three other horses followedsuit.', 'Once more, the Dover mail struggled on, with the jack-boots of itspassengers squashing along by its side.', 'They had stopped when the coachstopped, and they kept close company with it.', 'If any one of the threehad had the hardihood to propose to another to walk on a little aheadinto the mist and darkness, he would have put himself in a fair way ofgetting shot instantly as a highwayman.The last burst carried the mail to the summit of the hill.', 'The horsesstopped to breathe again, and the guard got down to skid the wheel forthe descent, and open the coach-door to let the passengers in.\"Tst!', 'Joe!\"', 'cried the coachman in a warning voice, looking down from hisbox.', '\"What do you say, Tom?', '\"They both listened.', '\"I say a horse at a canter coming up, Joe.', '\"\"_I_ say a horse at a gallop, Tom,\" returned the guard, leaving his holdof the door, and mounting nimbly to his place.', '\"Gentlemen!', \"In the king'sname, all of you!\", '\"With this hurried adjuration, he cocked his blunderbuss, and stood onthe offensive.The passenger booked by this history, was on the coach-step, getting in;the two other passengers were close behind him, and about to follow.', 'Heremained on the step, half in the coach and half out of; they remainedin the road below him.', 'They all looked from the coachman to the guard,and from the guard to the coachman, and listened.', 'The coachman lookedback and the guard looked back, and even the emphatic leader pricked uphis ears and looked back, without contradicting.The stillness consequent on the cessation of the rumbling and labouringof the coach, added to the stillness of the night, made it very quietindeed.', 'The panting of the horses communicated a tremulous motion tothe coach, as if it were in a state of agitation.', 'The hearts of thepassengers beat loud enough perhaps to be heard; but at any rate, thequiet pause was audibly expressive of people out of breath, and holdingthe breath, and having the pulses quickened by expectation.The sound of a horse at a gallop came fast and furiously up the hill.\"So-ho!\"', 'the guard sang out, as loud as he could roar.', '\"Yo there!', 'Stand!I shall fire!', '\"The pace was suddenly checked, and, with much splashing and floundering,a man\\'s voice called from the mist, \"Is that the Dover mail?', '\"\"Never you mind what it is!\"', 'the guard retorted.', '\"What are you?', '\"\"_Is_ that the Dover mail?', '\"\"Why do you want to know?', '\"\"I want a passenger, if it is.', '\"\"What passenger?\"\"Mr.', 'Jarvis Lorry.', '\"Our booked passenger showed in a moment that it was his name.', 'The guard,the coachman, and the two other passengers eyed him distrustfully.', '\"Keep where you are,\" the guard called to the voice in the mist,\"because, if I should make a mistake, it could never be set right inyour lifetime.', 'Gentleman of the name of Lorry answer straight.', '\"\"What is the matter?\"', 'asked the passenger, then, with mildly quaveringspeech.', '\"Who wants me?', 'Is it Jerry?', '\"(\"I don\\'t like Jerry\\'s voice, if it is Jerry,\" growled the guard tohimself.', '\"He\\'s hoarser than suits me, is Jerry.', '\")\"Yes, Mr.', 'Lorry.', '\"\"What is the matter?', '\"\"A despatch sent after you from over yonder.', 'T. and Co.\"\"I know this messenger, guard,\" said Mr. Lorry, getting down into theroad--assisted from behind more swiftly than politely by the other twopassengers, who immediately scrambled into the coach, shut the door, andpulled up the window.', '\"He may come close; there\\'s nothing wrong.', '\"\"I hope there ain\\'t, but I can\\'t make so \\'Nation sure of that,\" said theguard, in gruff soliloquy.', '\"Hallo you!\"\"Well!', 'And hallo you!\"', 'said Jerry, more hoarsely than before.', '\"Come on at a footpace!', \"d'ye mind me?\", \"And if you've got holsters to thatsaddle o' yourn, don't let me see your hand go nigh 'em.\", \"For I'm a devilat a quick mistake, and when I make one it takes the form of Lead.\", \"Sonow let's look at you.\", '\"The figures of a horse and rider came slowly through the eddying mist,and came to the side of the mail, where the passenger stood.', 'The riderstooped, and, casting up his eyes at the guard, handed the passengera small folded paper.', 'The rider\\'s horse was blown, and both horse andrider were covered with mud, from the hoofs of the horse to the hat ofthe man.\"Guard!\"', 'said the passenger, in a tone of quiet business confidence.The watchful guard, with his right hand at the stock of his raisedblunderbuss, his left at the barrel, and his eye on the horseman,answered curtly, \"Sir.', '\"\"There is nothing to apprehend.', \"I belong to Tellson's Bank.\", \"You mustknow Tellson's Bank in London.\", 'I am going to Paris on business.', 'A crownto drink.', 'I may read this?', '\"\"If so be as you\\'re quick, sir.', '\"He opened it in the light of the coach-lamp on that side, andread--first to himself and then aloud: \"\\'Wait at Dover for Mam\\'selle.', \"'It's not long, you see, guard.\", 'Jerry, say that my answer was, RECALLEDTO LIFE.', '\"Jerry started in his saddle.', '\"That\\'s a Blazing strange answer, too,\"said he, at his hoarsest.', '\"Take that message back, and they will know that I received this, aswell as if I wrote.', 'Make the best of your way.', 'Good night.', '\"With those words the passenger opened the coach-door and got in; not atall assisted by his fellow-passengers, who had expeditiously secretedtheir watches and purses in their boots, and were now making a generalpretence of being asleep.', 'With no more definite purpose than to escapethe hazard of originating any other kind of action.The coach lumbered on again, with heavier wreaths of mist closing roundit as it began the descent.', \"The guard soon replaced his blunderbussin his arm-chest, and, having looked to the rest of its contents, andhaving looked to the supplementary pistols that he wore in his belt,looked to a smaller chest beneath his seat, in which there were afew smith's tools, a couple of torches, and a tinder-box.\", 'For he wasfurnished with that completeness that if the coach-lamps had been blownand stormed out, which did occasionally happen, he had only to shuthimself up inside, keep the flint and steel sparks well off the straw,and get a light with tolerable safety and ease (if he were lucky) infive minutes.\"Tom!\"', 'softly over the coach roof.', '\"Hallo, Joe.', '\"\"Did you hear the message?', '\"\"I did, Joe.', '\"\"What did you make of it, Tom?', '\"\"Nothing at all, Joe.', '\"\"That\\'s a coincidence, too,\" the guard mused, \"for I made the same of itmyself.', '\"Jerry, left alone in the mist and darkness, dismounted meanwhile, notonly to ease his spent horse, but to wipe the mud from his face, andshake the wet out of his hat-brim, which might be capable ofholding about half a gallon.', 'After standing with the bridle over hisheavily-splashed arm, until the wheels of the mail were no longer withinhearing and the night was quite still again, he turned to walk down thehill.', '\"After that there gallop from Temple Bar, old lady, I won\\'t trust yourfore-legs till I get you on the level,\" said this hoarse messenger,glancing at his mare.', '\"\\'Recalled to life.\\'', \"That's a Blazing strangemessage.\", \"Much of that wouldn't do for you, Jerry!\", 'I say, Jerry!', 'You\\'dbe in a Blazing bad way, if recalling to life was to come into fashion,Jerry!\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def clean_text(txt):\n",
        "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
        "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return txt"
      ],
      "metadata": {
        "id": "W0kYQ2jO2qkT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [clean_text(x) for x in sentence]\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bM1CuvJ2x4B",
        "outputId": "cbb7a51f-da13-45ef-f018-44e06ffea5cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'the periodit was the best of timesit was the worst of timesit was the age of wisdomit was the age of foolishnessit was the epoch of beliefit was the epoch of incredulityit was the season of lightit was the season of darknessit was the spring of hopeit was the winter of despairwe had everything before uswe had nothing before uswe were all going direct to heavenwe were all going direct the other wayin short the period was so far like the present period that some ofits noisiest authorities insisted on its being received for good or forevil in the superlative degree of comparison onlythere were a king with a large jaw and a queen with a plain face on thethrone of england there were a king with a large jaw and a queen witha fair face on the throne of france',\n",
              " 'in both countries it was clearerthan crystal to the lords of the state preserves of loaves and fishesthat things in general were settled for everit was the year of our lord one thousand seven hundred and seventyfivespiritual revelations were conceded to england at that favoured periodas at this',\n",
              " 'mrs southcott had recently attained her fiveandtwentiethblessed birthday of whom a prophetic private in the life guards hadheralded the sublime appearance by announcing that arrangements weremade for the swallowing up of london and westminster',\n",
              " 'even the cocklaneghost had been laid only a round dozen of years after rapping out itsmessages as the spirits of this very year last past supernaturallydeficient in originality rapped out theirs',\n",
              " 'mere messages in theearthly order of events had lately come to the english crown and peoplefrom a congress of british subjects in america which strangeto relate have proved more important to the human race than anycommunications yet received through any of the chickens of the cocklanebroodfrance less favoured on the whole as to matters spiritual than hersister of the shield and trident rolled with exceeding smoothness downhill making paper money and spending it',\n",
              " 'under the guidance of herchristian pastors she entertained herself besides with such humaneachievements as sentencing a youth to have his hands cut off his tonguetorn out with pincers and his body burned alive because he had notkneeled down in the rain to do honour to a dirty procession of monkswhich passed within his view at a distance of some fifty or sixtyyards',\n",
              " 'it is likely enough that rooted in the woods of france andnorway there were growing trees when that sufferer was put to deathalready marked by the woodman fate to come down and be sawn intoboards to make a certain movable framework with a sack and a knife init terrible in history',\n",
              " 'it is likely enough that in the rough outhousesof some tillers of the heavy lands adjacent to paris there weresheltered from the weather that very day rude carts bespattered withrustic mire snuffed about by pigs and roosted in by poultry whichthe farmer death had already set apart to be his tumbrils ofthe revolution',\n",
              " 'but that woodman and that farmer though they workunceasingly work silently and no one heard them as they went aboutwith muffled tread the rather forasmuch as to entertain any suspicionthat they were awake was to be atheistical and traitorousin england there was scarcely an amount of order and protection tojustify much national boasting']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n"
      ],
      "metadata": {
        "id": "flf8PUxh3JoA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating n gram sequence for Training\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "def get_sequence_of_tokens(corpus):\n",
        "    ## tokenization\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    \n",
        "## convert data to sequence of tokens \n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(token_list)):\n",
        "            n_gram_sequence = token_list[:i+1]\n",
        "            input_sequences.append(n_gram_sequence)\n",
        "    return input_sequences, total_words"
      ],
      "metadata": {
        "id": "D09mqRK83KR6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
        "print(*inp_sequences[:10], sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBa042LH3bGI",
        "outputId": "9ddde9d7-47c2-4394-8202-0d6d31458dd0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 279]\n",
            "[1, 279, 7]\n",
            "[1, 279, 7, 1]\n",
            "[1, 279, 7, 1, 156]\n",
            "[1, 279, 7, 1, 156, 2]\n",
            "[1, 279, 7, 1, 156, 2, 157]\n",
            "[1, 279, 7, 1, 156, 2, 157, 7]\n",
            "[1, 279, 7, 1, 156, 2, 157, 7, 1]\n",
            "[1, 279, 7, 1, 156, 2, 157, 7, 1, 280]\n",
            "[1, 279, 7, 1, 156, 2, 157, 7, 1, 280, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import keras.utils as ku \n",
        "from keras import utils as np_utils\n",
        "from keras.utils.np_utils import to_categorical\n",
        "#from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "OX0ZdQzj3bJp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the sequence\n",
        "def generate_padded_sequences(input_sequences):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "    \n",
        "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "    label = to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, max_sequence_len"
      ],
      "metadata": {
        "id": "Om0OVB0C3bNw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
      ],
      "metadata": {
        "id": "g0MTrOB73bQ4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Creation\n",
        "def create_model(max_sequence_len, total_words):\n",
        "    input_len = max_sequence_len - 1\n",
        "    model = Sequential()\n",
        "    # ----------Add Input Embedding Layer\n",
        "    model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "    # ----------Add Hidden Layer 1 - LSTM Layer\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.1))\n",
        "    # ----------Add Output Layer\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    return model"
      ],
      "metadata": {
        "id": "ySBsg31n3bTa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(max_sequence_len, total_words)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Fr2giUC43bWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0ce390-1875-45a5-aab9-b9e5c0c71de5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 201, 10)           11190     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               44400     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1119)              113019    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,609\n",
            "Trainable params: 168,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "model.fit(predictors, label, epochs=95, verbose=95)"
      ],
      "metadata": {
        "id": "6qrCTQ2m3bbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cece7b5-fb99-4ef8-e85a-1ad22db89fbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/95\n",
            "Epoch 2/95\n",
            "Epoch 3/95\n",
            "Epoch 4/95\n",
            "Epoch 5/95\n",
            "Epoch 6/95\n",
            "Epoch 7/95\n",
            "Epoch 8/95\n",
            "Epoch 9/95\n",
            "Epoch 10/95\n",
            "Epoch 11/95\n",
            "Epoch 12/95\n",
            "Epoch 13/95\n",
            "Epoch 14/95\n",
            "Epoch 15/95\n",
            "Epoch 16/95\n",
            "Epoch 17/95\n",
            "Epoch 18/95\n",
            "Epoch 19/95\n",
            "Epoch 20/95\n",
            "Epoch 21/95\n",
            "Epoch 22/95\n",
            "Epoch 23/95\n",
            "Epoch 24/95\n",
            "Epoch 25/95\n",
            "Epoch 26/95\n",
            "Epoch 27/95\n",
            "Epoch 28/95\n",
            "Epoch 29/95\n",
            "Epoch 30/95\n",
            "Epoch 31/95\n",
            "Epoch 32/95\n",
            "Epoch 33/95\n",
            "Epoch 34/95\n",
            "Epoch 35/95\n",
            "Epoch 36/95\n",
            "Epoch 37/95\n",
            "Epoch 38/95\n",
            "Epoch 39/95\n",
            "Epoch 40/95\n",
            "Epoch 41/95\n",
            "Epoch 42/95\n",
            "Epoch 43/95\n",
            "Epoch 44/95\n",
            "Epoch 45/95\n",
            "Epoch 46/95\n",
            "Epoch 47/95\n",
            "Epoch 48/95\n",
            "Epoch 49/95\n",
            "Epoch 50/95\n",
            "Epoch 51/95\n",
            "Epoch 52/95\n",
            "Epoch 53/95\n",
            "Epoch 54/95\n",
            "Epoch 55/95\n",
            "Epoch 56/95\n",
            "Epoch 57/95\n",
            "Epoch 58/95\n",
            "Epoch 59/95\n",
            "Epoch 60/95\n",
            "Epoch 61/95\n",
            "Epoch 62/95\n",
            "Epoch 63/95\n",
            "Epoch 64/95\n",
            "Epoch 65/95\n",
            "Epoch 66/95\n",
            "Epoch 67/95\n",
            "Epoch 68/95\n",
            "Epoch 69/95\n",
            "Epoch 70/95\n",
            "Epoch 71/95\n",
            "Epoch 72/95\n",
            "Epoch 73/95\n",
            "Epoch 74/95\n",
            "Epoch 75/95\n",
            "Epoch 76/95\n",
            "Epoch 77/95\n",
            "Epoch 78/95\n",
            "Epoch 79/95\n",
            "Epoch 80/95\n",
            "Epoch 81/95\n",
            "Epoch 82/95\n",
            "Epoch 83/95\n",
            "Epoch 84/95\n",
            "Epoch 85/95\n",
            "Epoch 86/95\n",
            "Epoch 87/95\n",
            "Epoch 88/95\n",
            "Epoch 89/95\n",
            "Epoch 90/95\n",
            "Epoch 91/95\n",
            "Epoch 92/95\n",
            "Epoch 93/95\n",
            "Epoch 94/95\n",
            "Epoch 95/95\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c101d3510>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list],              maxlen=max_sequence_len-1, padding='pre')\n",
        "        #predicted = model.predict_classes(token_list, verbose=0)\n",
        "        predicted = np.argmax(model.predict(token_list),axis=1)       \n",
        "\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word,index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \"+output_word\n",
        "    return seed_text.title()"
      ],
      "metadata": {
        "id": "1FTCOFSpPiN_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set seeds for reproducability\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import random\n",
        "random.set_seed(2)"
      ],
      "metadata": {
        "id": "i11kQQShPiQh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (generate_text(\"mrs southcott had recently attained\", 3, model, max_sequence_len))\n",
        "print (generate_text(\"even the cocklaneghost\", 3, model, max_sequence_len))\n",
        "print (generate_text(\"mere messages in theearthly\", 4, model, max_sequence_len))\n"
      ],
      "metadata": {
        "id": "xKgQGp0SPiTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfcc6ac0-4fb2-4a3d-a91d-5ebe126f871b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mrs Southcott Had Recently Attained Her Fiveandtwentiethblessed Birthday\n",
            "Even The Cocklaneghost Had Been Laid\n",
            "Mere Messages In Theearthly Order Of The Name\n"
          ]
        }
      ]
    }
  ]
}